{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from  tensorflow import keras\n",
    "from  tensorflow.keras import layers\n",
    "import base64\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import re\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('train')))\n",
    "random.seed(SEED)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, resize it to 64x64 pixels (the required input spatial dimensions of SmallVGGNet), \n",
    "    # and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (224, 224))   # we are not flattening our data for neural network, because it is convolutional\n",
    "    images.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[1]\n",
    "    labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "images = np.array(images, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into 80% training and 20% validation\n",
    "(trainX, valX, trainY, valY) = train_test_split(images, labels, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3584, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "valY = lb.transform(valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (trainX.shape[1], trainX.shape[2], trainX.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "base_model.trainable = False ## Not trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(1024, activation='relu')\n",
    "# dropput_layer_1 = layers.Dropout(0.25)\n",
    "# dense_layer_2 = layers.Dense(512, activation='relu')\n",
    "prediction_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "#     dropput_layer_1,\n",
    "#     dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model/vgg_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "224/224 [==============================] - 27s 119ms/step - loss: 0.6782 - binary_accuracy: 0.5826 - val_loss: 0.6684 - val_binary_accuracy: 0.5960 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "224/224 [==============================] - 25s 113ms/step - loss: 0.6532 - binary_accuracy: 0.6102 - val_loss: 0.6484 - val_binary_accuracy: 0.6328 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "224/224 [==============================] - 25s 113ms/step - loss: 0.6354 - binary_accuracy: 0.6437 - val_loss: 0.6323 - val_binary_accuracy: 0.6484 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "224/224 [==============================] - 25s 112ms/step - loss: 0.6212 - binary_accuracy: 0.6682 - val_loss: 0.6187 - val_binary_accuracy: 0.6629 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "224/224 [==============================] - 25s 113ms/step - loss: 0.6056 - binary_accuracy: 0.6895 - val_loss: 0.6104 - val_binary_accuracy: 0.6663 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245124bdc10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 5\n",
    "BS = 32\n",
    "\n",
    "opt = SGD(INIT_LR)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"binary_accuracy\"])\n",
    "\n",
    "model.fit(aug.flow(trainX, trainY, batch_size=16), epochs=EPOCHS, validation_data=(valX, valY), batch_size=16, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=11, verbose=1, restore_best_weights=True),\n",
    "                    keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "224/224 [==============================] - 29s 128ms/step - loss: 0.6551 - binary_accuracy: 0.6155 - val_loss: 0.6568 - val_binary_accuracy: 0.5949 - lr: 1.0000e-06\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 25s 112ms/step - loss: 0.6557 - binary_accuracy: 0.6141 - val_loss: 0.6566 - val_binary_accuracy: 0.5938 - lr: 1.0000e-06\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 25s 111ms/step - loss: 0.6528 - binary_accuracy: 0.6175 - val_loss: 0.6564 - val_binary_accuracy: 0.5949 - lr: 1.0000e-06\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 25s 114ms/step - loss: 0.6554 - binary_accuracy: 0.6180 - val_loss: 0.6562 - val_binary_accuracy: 0.5960 - lr: 1.0000e-06\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 25s 113ms/step - loss: 0.6520 - binary_accuracy: 0.6194 - val_loss: 0.6560 - val_binary_accuracy: 0.5960 - lr: 1.0000e-06\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 25s 112ms/step - loss: 0.6543 - binary_accuracy: 0.6189 - val_loss: 0.6558 - val_binary_accuracy: 0.5971 - lr: 1.0000e-06\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 25s 111ms/step - loss: 0.6597 - binary_accuracy: 0.6044 - val_loss: 0.6556 - val_binary_accuracy: 0.5971 - lr: 1.0000e-06\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 25s 112ms/step - loss: 0.6541 - binary_accuracy: 0.6191 - val_loss: 0.6553 - val_binary_accuracy: 0.5982 - lr: 1.0000e-06\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 25s 112ms/step - loss: 0.6563 - binary_accuracy: 0.6147 - val_loss: 0.6551 - val_binary_accuracy: 0.5982 - lr: 1.0000e-06\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 25s 113ms/step - loss: 0.6576 - binary_accuracy: 0.6152 - val_loss: 0.6549 - val_binary_accuracy: 0.5993 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212043b8a60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(aug.flow(trainX, trainY, batch_size=16), epochs=5, validation_data=(valX, valY), batch_size=16, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=11, verbose=1, restore_best_weights=True),\n",
    "                    keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model/vgg_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "224/224 [==============================] - 40s 151ms/step - loss: 0.5580 - binary_accuracy: 0.7366 - val_loss: 0.5191 - val_binary_accuracy: 0.7679 - lr: 1.0000e-06\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.4832 - binary_accuracy: 0.7826 - val_loss: 0.4451 - val_binary_accuracy: 0.8013 - lr: 1.0000e-06\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.4061 - binary_accuracy: 0.8284 - val_loss: 0.4103 - val_binary_accuracy: 0.8080 - lr: 1.0000e-06\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.3472 - binary_accuracy: 0.8527 - val_loss: 0.3456 - val_binary_accuracy: 0.8493 - lr: 1.0000e-06\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.3026 - binary_accuracy: 0.8764 - val_loss: 0.2894 - val_binary_accuracy: 0.8817 - lr: 1.0000e-06\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 32s 144ms/step - loss: 0.2654 - binary_accuracy: 0.8901 - val_loss: 0.2688 - val_binary_accuracy: 0.8917 - lr: 1.0000e-06\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.2314 - binary_accuracy: 0.9090 - val_loss: 0.2265 - val_binary_accuracy: 0.9118 - lr: 1.0000e-06\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.2018 - binary_accuracy: 0.9302 - val_loss: 0.2103 - val_binary_accuracy: 0.9163 - lr: 1.0000e-06\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 32s 143ms/step - loss: 0.1807 - binary_accuracy: 0.9344 - val_loss: 0.1992 - val_binary_accuracy: 0.9174 - lr: 1.0000e-06\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 32s 144ms/step - loss: 0.1517 - binary_accuracy: 0.9464 - val_loss: 0.1787 - val_binary_accuracy: 0.9297 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24540da7250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "opt = Adam(1e-6)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"binary_accuracy\"])\n",
    "\n",
    "model.fit(aug.flow(trainX, trainY, batch_size=16), epochs=EPOCHS, validation_data=(valX, valY), batch_size=16, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=11, verbose=1, restore_best_weights=True),\n",
    "                    keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model/vgg_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading test images...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading test images...\")\n",
    "testData = []\n",
    "testLabel = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "testImagePaths = sorted(list(paths.list_images('test')))\n",
    "random.seed(SEED)\n",
    "random.shuffle(testImagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in testImagePaths:\n",
    "    # load the image, resize it to 64x64 pixels (the required input spatial dimensions of SmallVGGNet), \n",
    "    # and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (224, 224))   # we are not flattening our data for neural network, because it is convolutional\n",
    "    testData.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[1]\n",
    "    testLabel.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "testData = np.array(testData, dtype=\"float\") / 255.0\n",
    "testLabel = np.array(testLabel)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2046, 224, 224, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = lb.transform(testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "testY = lb.fit_transform(testLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model/vgg_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 7s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testData,  batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      1271\n",
      "           1       0.61      0.63      0.62       775\n",
      "\n",
      "    accuracy                           0.70      2046\n",
      "   macro avg       0.69      0.69      0.69      2046\n",
      "weighted avg       0.71      0.70      0.70      2046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions =  (predictions>0.5)\n",
    "print(classification_report(testY, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vgg_test_accuracy_70.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
